{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Augmentation Tutorial | Classification Preperation\n\n### In this notebook, my purpose is to show you to usage of albumentation with saved augmented data. That particular operation may be vital for our datasets because sometimes we can not get same results without saving the augmentations...","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import Dataset, DataLoader\n\nimport io\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nfrom glob import glob\nfrom tqdm import tqdm\nimport warnings\nimport pandas as pd\n\nimport albumentations as A\nfrom PIL import Image\nimport cv2\nfrom albumentations.pytorch import ToTensorV2\nwarnings.simplefilter('ignore')\n\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nprint(torch.cuda.get_device_name())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-20T05:22:59.666385Z","iopub.execute_input":"2022-09-20T05:22:59.666883Z","iopub.status.idle":"2022-09-20T05:23:03.222940Z","shell.execute_reply.started":"2022-09-20T05:22:59.666788Z","shell.execute_reply":"2022-09-20T05:23:03.221899Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"cuda:0\nTesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### We will specify our class labels in order to get correct labels when increasing our dataset size. In ClassificationDataset, we are aiming to preprocess the data and return label and images...","metadata":{}},{"cell_type":"code","source":"class ClassificationDataset(Dataset):\n    def __init__(self, images_filepaths, transform=None):\n        self.images_filepaths = images_filepaths\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images_filepaths)\n\n    def __getitem__(self, idx):\n        image_filepath = self.images_filepaths[idx]\n        image = cv2.imread(image_filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if os.path.normpath(image_filepath).split(os.sep)[-2] == \"birds\":\n            label = 0\n        else:\n            label = 1\n        if self.transform is not None:\n            image = self.transform(image=image)[\"image\"]\n\n        return image, label\n","metadata":{"execution":{"iopub.status.busy":"2022-09-20T05:23:03.227421Z","iopub.execute_input":"2022-09-20T05:23:03.230222Z","iopub.status.idle":"2022-09-20T05:23:03.242166Z","shell.execute_reply.started":"2022-09-20T05:23:03.230176Z","shell.execute_reply":"2022-09-20T05:23:03.240079Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### I generally use splitfolders in order to split my training-test-validation datas. \n\n### ratio=(train size,val size,test size)","metadata":{}},{"cell_type":"code","source":"!pip install split-folders\nimport splitfolders\n\npath='../input/drone-bird-classification/drone_or_bird'\nsplitfolders.ratio(path,ratio=(0.7,0.2,0.1))","metadata":{"execution":{"iopub.status.busy":"2022-09-20T05:27:34.138446Z","iopub.execute_input":"2022-09-20T05:27:34.138788Z","iopub.status.idle":"2022-09-20T05:27:45.424092Z","shell.execute_reply.started":"2022-09-20T05:27:34.138759Z","shell.execute_reply":"2022-09-20T05:27:45.422871Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: split-folders in /opt/conda/lib/python3.7/site-packages (0.5.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"Copying files: 330 files [00:01, 227.24 files/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"class_names = os.listdir('../input/drone-bird-classification/drone_or_bird')\nclass_names","metadata":{"execution":{"iopub.status.busy":"2022-09-20T05:33:26.672380Z","iopub.execute_input":"2022-09-20T05:33:26.672765Z","iopub.status.idle":"2022-09-20T05:33:26.684207Z","shell.execute_reply.started":"2022-09-20T05:33:26.672734Z","shell.execute_reply":"2022-09-20T05:33:26.683242Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['birds', 'drones']"},"metadata":{}}]},{"cell_type":"markdown","source":"### With glob we are taking our file paths...","metadata":{}},{"cell_type":"code","source":"datasets={\n        'train':[],\n        'val':[],\n        'test':[]\n    }\nfor phase in ['train','val','test']:\n    l=[]\n    for i in glob(f'./output/{phase}/**/*'):\n        l.append(i)\n    datasets[phase]=l","metadata":{"execution":{"iopub.status.busy":"2022-09-20T05:33:27.893331Z","iopub.execute_input":"2022-09-20T05:33:27.893699Z","iopub.status.idle":"2022-09-20T05:33:27.901979Z","shell.execute_reply.started":"2022-09-20T05:33:27.893668Z","shell.execute_reply":"2022-09-20T05:33:27.900949Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### We can determine our specific augmentation details like this. For more information you can visit https://albumentations.ai/docs/","metadata":{}},{"cell_type":"code","source":"train_transform = A.Compose(\n    [   A.Resize(height=180, width=180),\n        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n        A.RandomBrightnessContrast(p=0.5),\n        A.ColorJitter(),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ToTensorV2(),\n    ]\n)\noriginal_transform = A.Compose(\n    [   A.Resize(180,180),\n        A.CenterCrop(height=128, width=128),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ToTensorV2(),\n    ]\n)\nalb_dataset = ClassificationDataset(images_filepaths=datasets['train'], transform=train_transform)\noriginal_dataset=ClassificationDataset(images_filepaths=datasets['train'], transform=original_transform)\n\ndataset_sizes = {x: len(datasets[x]) for x in ['train', 'val']}\nclass_names = ['birds','drones']\ndataset_sizes","metadata":{"execution":{"iopub.status.busy":"2022-09-20T05:33:38.658800Z","iopub.execute_input":"2022-09-20T05:33:38.659701Z","iopub.status.idle":"2022-09-20T05:33:38.672114Z","shell.execute_reply.started":"2022-09-20T05:33:38.659653Z","shell.execute_reply":"2022-09-20T05:33:38.670984Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'train': 230, 'val': 66}"},"metadata":{}}]},{"cell_type":"markdown","source":"### We need folders for our augmented images so we are creating them and saving them with unique names.","metadata":{}},{"cell_type":"code","source":"import uuid\ntry:\n    os.mkdir('./prepdata')\n    os.mkdir('./prepdata/train')\n    os.mkdir('./prepdata/train/birds')\n    os.mkdir('./prepdata/train/drones')\n   \nexcept:\n    print('Dosyalar var')\n\ndef OriginalSave(originalDataset,limit):\n    s={0:'birds',1:'drones'}\n    originalDataset.transform = A.Compose([t for t in originalDataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n    \n    for idx in range(limit):\n        try:\n            image,label=originalDataset[idx]\n\n            cv2.imwrite(f'./prepdata/{s[label]}/{str(uuid.uuid4())}.jpg',image)\n        except:\n            print('Error')\nOriginalSave(original_dataset, dataset_sizes['train'])","metadata":{"execution":{"iopub.status.busy":"2022-09-20T05:35:28.648146Z","iopub.execute_input":"2022-09-20T05:35:28.648633Z","iopub.status.idle":"2022-09-20T05:35:32.376137Z","shell.execute_reply.started":"2022-09-20T05:35:28.648599Z","shell.execute_reply":"2022-09-20T05:35:32.375056Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Dosyalar var\nError\nError\nError\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### In this function, we will be generating the augmented images. Also with that operation, we can balance our data with for loops by specifying the range values.","metadata":{}},{"cell_type":"code","source":"def AlbSave(albDataset,limit):\n    s={0:'birds',1:'drones'}\n    sizes={'birds':165,'drones':165}\n\n    albDataset.transform = A.Compose([t for t in albDataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n    for idx in range(limit):\n        for _ in range(4):\n            try:\n                image,label=albDataset[idx]\n                if label==0:\n                    cv2.imwrite(f'./prepdata/train/{s[label]}/{str(uuid.uuid4())}.jpg',image)\n            except:\n                print('Error')\n\n        for _ in range(4):\n            try:\n                image,label=albDataset[idx]\n                if label==1:\n                    cv2.imwrite(f'./prepdata/train/{s[label]}/{str(uuid.uuid4())}.jpg',image)\n            except:\n                print('Error')\n\n\nAlbSave(alb_dataset,dataset_sizes['train'])","metadata":{"execution":{"iopub.status.busy":"2022-09-20T05:36:40.166779Z","iopub.execute_input":"2022-09-20T05:36:40.167353Z","iopub.status.idle":"2022-09-20T05:37:10.751359Z","shell.execute_reply.started":"2022-09-20T05:36:40.167317Z","shell.execute_reply":"2022-09-20T05:37:10.750403Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Error\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### It appears, that some images are problematic. These errors do not arise based on the code...","metadata":{}},{"cell_type":"code","source":"import shutil\nshutil.move('./output/val','./prepdata/')","metadata":{"execution":{"iopub.status.busy":"2022-09-20T05:38:31.501394Z","iopub.execute_input":"2022-09-20T05:38:31.501778Z","iopub.status.idle":"2022-09-20T05:38:31.508609Z","shell.execute_reply.started":"2022-09-20T05:38:31.501743Z","shell.execute_reply":"2022-09-20T05:38:31.507614Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'./prepdata/val'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}